---
sidebar_position: 4
sidebar_label: "Data Formatting & Processing"
---

# Data Flow to the Blockchain: Process and Architecture

## Overview of Data Integration

RedStone’s price feeds are sourced from a wide array of platforms, including centralized exchanges like Binance and Coinbase, decentralized exchanges (DEXs) such as Uniswap and Sushiswap, and price aggregators like CoinMarketCap and CoinGecko. With over 150 integrated sources, RedStone ensures that data is aggregated by independent nodes using methodologies like median, Time-Weighted Average Price (TWAP), and Liquidity-Weighted Average Price (LWAP). These methods focus on capturing accurate prices by accounting for factors such as available liquidity and price averages over specific timeframes.

To maintain data quality, RedStone employs outlier detection mechanisms to filter unexpected values. The processed data is then signed by node operators to guarantee its integrity. These data feeds are distributed through the Streamr decentralized network and open-source gateways, which can be easily deployed if needed.

Data can be pushed to the blockchain by a dedicated relayer operating under predefined conditions (e.g., specific price changes), a bot (e.g., performing liquidations), or even by end users interacting with the protocol. Once inside the protocol, the data is unpacked and cryptographically verified, ensuring the authenticity and accuracy of both its origin and timestamp.

## Data Encoding and Processing

### Context: Understanding Data Transfer to the Blockchain

When transferring data to a blockchain, an additional payload is added to the user’s transaction, which is then processed on-chain. This means that data, such as a cryptocurrency’s price, is embedded within the transaction data. Because blockchains transition from one state to another and contain call data, RedStone can insert its data into the call data of a user’s transaction, effectively recording the data on the blockchain.

### How Data is Encoded Before Blockchain Submission

_Note: All steps are automatically handled by the ContractWrapper, making the process transparent to the end user._

1. **Data Retrieval**: Relevant data is fetched from the data distribution layer, powered by the Streamr network or RedStone gateways.
2. **Data Packaging**: The data is structured according to the ‘Transaction Payload’ diagram.
   
<a href="https://raw.githubusercontent.com/redstone-finance/redstone-docs/main/static/img/redstone-tx-wrapping.png">
 <img src="/img/redstone-tx-wrapping.png" target="_blank"/>
</a>

3. **Data Submission**: The package is appended to the original transaction message, signed, and submitted to the network.

### On-Chain Data Processing: Unpacking, Verification, and Aggregation

1. **Unpacking**: The appended data packages are extracted from the call data.
2. **Verification**: Security checks are performed, including signature verification from trusted providers and timestamp validation to confirm data accuracy.
3. **Aggregation**: 
   - RedStone calculates the number of received unique signers for each requested data feed.
   - The median value of all the values provided by unique signers is calculated and used as the default value.
   - This process is optimized using low-level assembly code to minimize gas consumption.
4. **Security Mechanisms**: 
   - RedStone’s on-chain aggregation mechanism ensures that a minimum number of distinct data feeds are required.
   - Values from different providers are aggregated before being returned to the consumer contract.
   - The default aggregation method is median value calculation, ensuring that even if a small subset of providers is compromised, it does not significantly affect the final value.

## Technical Guidelines for Implementing RedStone Data Feeds

### Key On-Chain Aggregation Parameters

- **`getUniqueSignersThreshold` Function**  
  Purpose: Determines the minimum number of unique signers required to validate a piece of data. This ensures data accuracy and integrity by relying on multiple independent signers.
  
- **`getAuthorisedSignerIndex` Function**  
  Purpose: Returns the index of an authorized signer from a list of signers, verifying whether a given signer is authorized to sign data.
  
- **`aggregateValues` Function (for numeric values)**  
  Purpose: Aggregates numeric values from multiple data points, typically calculating an average or median to mitigate the impact of any single erroneous data point.
  
- **`aggregateByteValues` Function (for byte arrays)**  
  Purpose: Aggregates values specifically for byte arrays.

### Supported Data Types

RedStone supports two types of data in a contract:

1. Numeric 256-bit values (default)
2. Byte arrays with dynamic size

### Security Best Practices

- **Threshold Modification**: Overriding `getUniqueSignersThreshold` can be risky. Only proceed if you are absolutely confident in your changes.
- **Timestamp Validation**: Pay close attention to the timestamp validation logic. In certain use cases (e.g., synthetic DEX), you may need to cache the latest values in your contract storage to prevent arbitrage attacks.
- **Upgradability**: Implement a secure upgradability mechanism for your contract, preferably using multi-sig or DAO governance.
- **Monitoring**: Continuously monitor the RedStone data services registry and promptly update signer authorization logic in your contracts in case of changes. We will also notify you if you are a paying client.

### Implementation Recommendations

- **Data Feed Requests**: Design your smart contracts to minimize the number of data feeds requested in a single transaction.
- **Signer Threshold**: We recommend requiring approximately three unique signers to balance security with gas efficiency.

## Performance Benchmarks

You can check the benchmarks script and reports [here.](https://github.com/redstone-finance/redstone-oracles-monorepo/tree/main/packages/evm-connector/benchmarks)

<a href="https://raw.githubusercontent.com/redstone-finance/redstone-docs/main/static/img/architecture.png">
 <img src="/img/architecture.png" target="_blank"/>
</a>
